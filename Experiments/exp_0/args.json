{
    "batch_size": 1024,
    "epochs": 20,
    "learning_rate": 0.001,
    "lamda": 1e-05,
    "dim": 16,
    "layers": [
        16,
        16
    ],
    "dataset": "gorwala",
    "dropout": 0.0,
    "ks": [
        20,
        40,
        60,
        80,
        100
    ],
    "device": "gpu",
    "exp": null,
    "verbose": 2
}